{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_train_test_dirs(base_path):\n",
    "    \"\"\"Create train and test directories within the base path\"\"\"\n",
    "    train_dir = os.path.join(base_path, 'train')\n",
    "    test_dir = os.path.join(base_path, 'test')\n",
    "    \n",
    "    for dir_path in [train_dir, test_dir]:\n",
    "        if not os.path.exists(dir_path):\n",
    "            os.makedirs(dir_path)\n",
    "    \n",
    "    return train_dir, test_dir\n",
    "\n",
    "def split_data(base_path, split_ratio=0.7):\n",
    "    \"\"\"Split data from base path into train and test sets\"\"\"\n",
    "    # Get all image files from base directory\n",
    "    image_files = [f for f in os.listdir(base_path) \n",
    "                  if f.endswith(('.jpg', '.jpeg', '.png')) \n",
    "                  and os.path.isfile(os.path.join(base_path, f))]\n",
    "    \n",
    "    # Create train/test directories\n",
    "    train_dir, test_dir = create_train_test_dirs(base_path)\n",
    "    \n",
    "    # Split the data\n",
    "    train_files, test_files = train_test_split(image_files, \n",
    "                                             train_size=split_ratio, \n",
    "                                             random_state=42)\n",
    "    \n",
    "    # Move files to respective directories\n",
    "    for file in train_files:\n",
    "        src = os.path.join(base_path, file)\n",
    "        dst = os.path.join(train_dir, file)\n",
    "        shutil.move(src, dst)\n",
    "    \n",
    "    for file in test_files:\n",
    "        src = os.path.join(base_path, file)\n",
    "        dst = os.path.join(test_dir, file)\n",
    "        shutil.move(src, dst)\n",
    "    \n",
    "    print(f\"Total images: {len(image_files)}\")\n",
    "    print(f\"Training images: {len(train_files)}\")\n",
    "    print(f\"Testing images: {len(test_files)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set your base path where images are located\n",
    "    base_path = \"dataset\"\n",
    "    \n",
    "    # Split and move data\n",
    "    split_data(base_path, split_ratio=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define paths\n",
    "train_path = os.path.join(\"dataset\", \"train\")  # Path to training data\n",
    "augmented_path = os.path.join(\"dataset\", \"train_augmented\")\n",
    "\n",
    "os.makedirs(augmented_path, exist_ok=True)\n",
    "\n",
    "def get_next_image_number(train_path):\n",
    "    \"\"\"Find the highest image number in the existing files and return next number\"\"\"\n",
    "    existing_files = [f for f in os.listdir(train_path) if f.lower().endswith(('png', 'jpg', 'jpeg'))]\n",
    "    numbers = []\n",
    "    \n",
    "    for f in existing_files:\n",
    "        try:\n",
    "            # Extract number from filenames like 'IMG_102.jpg'\n",
    "            num = int(f.split('_')[1].split('.')[0])\n",
    "            numbers.append(num)\n",
    "        except (IndexError, ValueError):\n",
    "            continue\n",
    "\n",
    "    return max(numbers) + 1 if numbers else 102  # Start numbering from 102 if no images exist\n",
    "\n",
    "# Get list of training images\n",
    "train_files = [f for f in os.listdir(train_path) if f.lower().endswith(('png', 'jpg', 'jpeg'))]\n",
    "next_image_number = get_next_image_number(train_path)\n",
    "\n",
    "# Define augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Function to save augmented images\n",
    "def save_augmented_image(image, number):\n",
    "    filename = f'IMG_{number:03d}.jpg'\n",
    "    cv2.imwrite(os.path.join(augmented_path, filename), image)\n",
    "\n",
    "# Apply augmentation\n",
    "num_augmented = 0\n",
    "for file in train_files:\n",
    "    img_path = os.path.join(train_path, file)\n",
    "    image = cv2.imread(img_path)\n",
    "    \n",
    "    if image is None:\n",
    "        continue  # Skip invalid images\n",
    "\n",
    "    image = np.expand_dims(image, axis=0)  # Expand dimensions to match ImageDataGenerator input\n",
    "\n",
    "    # Generate augmented images\n",
    "    aug_iter = datagen.flow(image, batch_size=1)\n",
    "\n",
    "    for i in range(5):  # Generate 5 augmented versions per image\n",
    "        aug_image = next(aug_iter)[0].astype(np.uint8)\n",
    "        save_augmented_image(aug_image, next_image_number)\n",
    "        next_image_number += 1\n",
    "        num_augmented += 1\n",
    "\n",
    "print(f'Generated {num_augmented} augmented images in {augmented_path}')\n",
    "\n",
    "# Move augmented images to training directory\n",
    "for aug_file in os.listdir(augmented_path):\n",
    "    src = os.path.join(augmented_path, aug_file)\n",
    "    dst = os.path.join(train_path, aug_file)\n",
    "    shutil.move(src, dst)\n",
    "\n",
    "# Remove temporary augmented directory\n",
    "os.rmdir(augmented_path)\n",
    "\n",
    "print(f'Moved all augmented images to training directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import warnings  # Add this import\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.mps\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import functional as F\n",
    "# Fix for circular import - import specific components instead of full modules\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50\n",
    "from torchvision.transforms import ToTensor, Resize, Normalize, Compose\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Attention Block for focusing on relevant features\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels // 8, kernel_size=1),\n",
    "            nn.BatchNorm2d(in_channels // 8),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels // 8, in_channels, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        attention_weights = self.attention(x)\n",
    "        return x * attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASPP Module for multi-scale feature extraction\n",
    "class ASPPModule(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 1)\n",
    "        self.conv3_1 = nn.Conv2d(in_channels, out_channels, 3, padding=1, dilation=1)\n",
    "        self.conv3_6 = nn.Conv2d(in_channels, out_channels, 3, padding=6, dilation=6)\n",
    "        self.conv3_12 = nn.Conv2d(in_channels, out_channels, 3, padding=12, dilation=12)\n",
    "        self.bn = nn.BatchNorm2d(out_channels * 4)\n",
    "        self.conv1x1 = nn.Conv2d(out_channels * 4, out_channels, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        conv1 = self.conv1(x)\n",
    "        conv3_1 = self.conv3_1(x)\n",
    "        conv3_6 = self.conv3_6(x)\n",
    "        conv3_12 = self.conv3_12(x)\n",
    "        concat = torch.cat([conv1, conv3_1, conv3_6, conv3_12], dim=1)\n",
    "        return self.conv1x1(self.bn(concat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved Segmentation Model\n",
    "class ImprovedSegmentationModel(nn.Module):\n",
    "    def __init__(self, n_classes=1):\n",
    "        super().__init__()\n",
    "        # Change the model initialization\n",
    "        resnet = resnet50(weights='IMAGENET1K_V1')\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder1 = nn.Sequential(*list(resnet.children())[:3])\n",
    "        self.encoder2 = nn.Sequential(*list(resnet.children())[3:5])\n",
    "        self.encoder3 = list(resnet.children())[5]\n",
    "        self.encoder4 = list(resnet.children())[6]\n",
    "        self.encoder5 = list(resnet.children())[7]\n",
    "        \n",
    "        # Attention blocks\n",
    "        self.attention1 = AttentionBlock(256)\n",
    "        self.attention2 = AttentionBlock(512)\n",
    "        self.attention3 = AttentionBlock(1024)\n",
    "        \n",
    "        # ASPP module\n",
    "        self.aspp = ASPPModule(2048, 256)\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 256, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.decoder3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(1280, 128, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.decoder2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(640, 64, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.decoder1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(320, 32, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.final_conv = nn.Sequential(\n",
    "            nn.Conv2d(32, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(16, n_classes, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encoding\n",
    "        e1 = self.encoder1(x)\n",
    "        e2 = self.encoder2(e1)\n",
    "        e3 = self.encoder3(e2)\n",
    "        e4 = self.encoder4(e3)\n",
    "        e5 = self.encoder5(e4)\n",
    "        \n",
    "        # Apply attention\n",
    "        a2 = self.attention1(e2)\n",
    "        a3 = self.attention2(e3)\n",
    "        a4 = self.attention3(e4)\n",
    "        \n",
    "        # Apply ASPP\n",
    "        aspp_out = self.aspp(e5)\n",
    "        \n",
    "        # Decoding with skip connections and attention\n",
    "        d4 = self.decoder4(aspp_out)\n",
    "        d4_concat = torch.cat([d4, a4], dim=1)\n",
    "        \n",
    "        d3 = self.decoder3(d4_concat)\n",
    "        d3_concat = torch.cat([d3, a3], dim=1)\n",
    "        \n",
    "        d2 = self.decoder2(d3_concat)\n",
    "        d2_concat = torch.cat([d2, a2], dim=1)\n",
    "        \n",
    "        d1 = self.decoder1(d2_concat)\n",
    "        \n",
    "        # Final convolution\n",
    "        out = self.final_conv(d1)\n",
    "        \n",
    "        # Resize to input size\n",
    "        out = F.interpolate(out, size=x.shape[2:], mode='bilinear', align_corners=True)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace CombinedLoss with DiceLoss\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1e-5):\n",
    "        super().__init__()\n",
    "        self.smooth = smooth\n",
    "        \n",
    "    def forward(self, pred, target):\n",
    "        intersection = torch.sum(pred * target)\n",
    "        union = torch.sum(pred) + torch.sum(target)\n",
    "        dice = (2.0 * intersection + self.smooth) / (union + self.smooth)\n",
    "        return 1.0 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(pred, target):\n",
    "    \"\"\"Calculate Accuracy, IoU, Precision, Recall, F1 Score\"\"\"\n",
    "    pred = (pred > 0.5).float()\n",
    "    \n",
    "    tp = torch.sum(pred * target)\n",
    "    fp = torch.sum(pred * (1 - target))\n",
    "    fn = torch.sum((1 - pred) * target)\n",
    "    tn = torch.sum((1 - pred) * (1 - target))\n",
    "    \n",
    "    accuracy = (tp + tn) / (tp + fp + fn + tn + 1e-6)\n",
    "    precision = tp / (tp + fp + 1e-6)\n",
    "    recall = tp / (tp + fn + 1e-6)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + 1e-6)\n",
    "    iou = tp / (tp + fp + fn + 1e-6)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy.item(),\n",
    "        'precision': precision.item(),\n",
    "        'recall': recall.item(),\n",
    "        'f1': f1.item(),\n",
    "        'iou': iou.item()\n",
    "    }\n",
    "\n",
    "def calculate_iou(pred, target):\n",
    "    \"\"\"Calculate IoU score\"\"\"\n",
    "    pred = (pred > 0.5).float()\n",
    "    intersection = (pred * target).sum()\n",
    "    union = pred.sum() + target.sum() - intersection\n",
    "    return (intersection + 1e-6) / (union + 1e-6)\n",
    "\n",
    "def calculate_dice_score(pred, target):\n",
    "    \"\"\"Calculate Dice score\"\"\"\n",
    "    pred = (pred > 0.5).float()\n",
    "    intersection = (pred * target).sum()\n",
    "    return (2. * intersection + 1e-6) / (pred.sum() + target.sum() + 1e-6)\n",
    "\n",
    "def get_training_config():\n",
    "    return {\n",
    "        'batch_size': 8,  # Increased batch size for faster processing\n",
    "        'num_workers': 2,  # Added some workers for data loading\n",
    "        'pin_memory': True,\n",
    "        'prefetch_factor': 2,  # Add prefetching for better data loading\n",
    "    }\n",
    "\n",
    "def plot_metrics(metrics_history, output_folder):\n",
    "    \"\"\"Plot training and validation metrics\"\"\"\n",
    "    metrics = ['loss', 'accuracy', 'precision', 'recall', 'f1', 'iou']\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    \n",
    "    for idx, metric in enumerate(metrics, 1):\n",
    "        plt.subplot(3, 2, idx)\n",
    "        plt.plot(metrics_history['train'][metric], label=f'Train {metric}')\n",
    "        plt.plot(metrics_history['val'][metric], label=f'Val {metric}')\n",
    "        plt.title(f'{metric.capitalize()} over epochs')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(metric.capitalize())\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_folder, 'training_metrics.png'))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device, output_folder):\n",
    "    best_val_metrics = {'dice': 0.0, 'f1': 0.0}\n",
    "    metrics_history = {\n",
    "        'train': {'loss': [], 'accuracy': [], 'dice': [], 'precision': [], 'recall': [], 'f1': [], 'iou': []},\n",
    "        'val': {'loss': [], 'accuracy': [], 'dice': [], 'precision': [], 'recall': [], 'f1': [], 'iou': []}\n",
    "    }\n",
    "    \n",
    "    # Create progress logger with additional metrics\n",
    "    metrics_file = os.path.join(output_folder, 'training_metrics.csv')\n",
    "    with open(metrics_file, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Epoch', 'Train_Loss', 'Train_Accuracy', 'Train_Dice', 'Train_Precision', \n",
    "                        'Train_Recall', 'Train_F1', 'Train_IoU', 'Val_Loss', 'Val_Accuracy',\n",
    "                        'Val_Dice', 'Val_Precision', 'Val_Recall', 'Val_F1', 'Val_IoU'])\n",
    "    \n",
    "    # Enable cuDNN autotuner\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_metrics = {'loss': 0, 'accuracy': 0, 'dice': 0, 'precision': 0, 'recall': 0, 'f1': 0, 'iou': 0}\n",
    "        \n",
    "        # Modified progress bar with all metrics\n",
    "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "        \n",
    "        for batch_idx, (images, masks) in enumerate(progress_bar):\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            \n",
    "            # Calculate all metrics for this batch\n",
    "            dice_score = 1 - loss.item()\n",
    "            batch_metrics = calculate_metrics(outputs, masks)\n",
    "            \n",
    "            # Update metrics\n",
    "            train_metrics['loss'] += loss.item()\n",
    "            train_metrics['accuracy'] += batch_metrics['accuracy']\n",
    "            train_metrics['dice'] += dice_score\n",
    "            train_metrics['precision'] += batch_metrics['precision']\n",
    "            train_metrics['recall'] += batch_metrics['recall']\n",
    "            train_metrics['f1'] += batch_metrics['f1']\n",
    "            train_metrics['iou'] += batch_metrics['iou']\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update progress bar with all metrics\n",
    "            progress_bar.set_postfix({\n",
    "                'loss': f\"{loss.item():.4f}\",\n",
    "                'accuracy': f\"{batch_metrics['accuracy']:.4f}\",\n",
    "                'dice': f\"{dice_score:.4f}\",\n",
    "                'prec': f\"{batch_metrics['precision']:.4f}\",\n",
    "                'rec': f\"{batch_metrics['recall']:.4f}\",\n",
    "                'f1': f\"{batch_metrics['f1']:.4f}\",\n",
    "                'iou': f\"{batch_metrics['iou']:.4f}\"\n",
    "            })\n",
    "        \n",
    "        # Calculate average training metrics\n",
    "        num_batches = len(train_loader)\n",
    "        for k in train_metrics:\n",
    "            train_metrics[k] /= num_batches\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_metrics = {'loss': 0, 'accuracy': 0, 'dice': 0, 'precision': 0, 'recall': 0, 'f1': 0, 'iou': 0}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, masks in val_loader:\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, masks)\n",
    "                \n",
    "                # Calculate metrics\n",
    "                dice_score = 1 - loss.item()\n",
    "                batch_metrics = calculate_metrics(outputs, masks)\n",
    "                \n",
    "                # Update metrics\n",
    "                val_metrics['loss'] += loss.item()\n",
    "                val_metrics['accuracy'] += batch_metrics['accuracy']\n",
    "                val_metrics['dice'] += dice_score\n",
    "                val_metrics['precision'] += batch_metrics['precision']\n",
    "                val_metrics['recall'] += batch_metrics['recall']\n",
    "                val_metrics['f1'] += batch_metrics['f1']\n",
    "                val_metrics['iou'] += batch_metrics['iou']\n",
    "        \n",
    "        # Calculate average validation metrics\n",
    "        num_val_batches = len(val_loader)\n",
    "        for k in val_metrics:\n",
    "            val_metrics[k] /= num_val_batches\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(val_metrics['loss'])\n",
    "        \n",
    "        # Save metrics\n",
    "        with open(metrics_file, 'a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\n",
    "                epoch + 1,\n",
    "                f\"{train_metrics['loss']:.4f}\",\n",
    "                f\"{train_metrics['accuracy']:.4f}\",\n",
    "                f\"{train_metrics['dice']:.4f}\",\n",
    "                f\"{train_metrics['precision']:.4f}\",\n",
    "                f\"{train_metrics['recall']:.4f}\",\n",
    "                f\"{train_metrics['f1']:.4f}\",\n",
    "                f\"{train_metrics['iou']:.4f}\",\n",
    "                f\"{val_metrics['loss']:.4f}\",\n",
    "                f\"{val_metrics['accuracy']:.4f}\",\n",
    "                f\"{val_metrics['dice']:.4f}\",\n",
    "                f\"{val_metrics['precision']:.4f}\",\n",
    "                f\"{val_metrics['recall']:.4f}\",\n",
    "                f\"{val_metrics['f1']:.4f}\",\n",
    "                f\"{val_metrics['iou']:.4f}\"\n",
    "            ])\n",
    "        \n",
    "        # Print epoch summary\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Train - Loss: {train_metrics['loss']:.4f}, Accuracy: {train_metrics['accuracy']:.4f}, Dice: {train_metrics['dice']:.4f}, \"\n",
    "              f\"F1: {train_metrics['f1']:.4f}, Precision: {train_metrics['precision']:.4f}, \"\n",
    "              f\"Recall: {train_metrics['recall']:.4f}, IoU: {train_metrics['iou']:.4f}\")\n",
    "        print(f\"Val - Loss: {val_metrics['loss']:.4f}, Accuracy: {val_metrics['accuracy']:.4f}, Dice: {val_metrics['dice']:.4f}, \"\n",
    "              f\"F1: {val_metrics['f1']:.4f}, Precision: {val_metrics['precision']:.4f}, \"\n",
    "              f\"Recall: {val_metrics['recall']:.4f}, IoU: {val_metrics['iou']:.4f}\")\n",
    "        \n",
    "    \n",
    "        print(f\"Saved new best model with dice score: {val_metrics['dice']:.4f}\")\n",
    "        \n",
    "        # Store metrics history\n",
    "        for phase in ['train', 'val']:\n",
    "            metrics = train_metrics if phase == 'train' else val_metrics\n",
    "            for k in metrics:\n",
    "                metrics_history[phase][k].append(metrics[k])\n",
    "    \n",
    "    # After training completes, plot the metrics\n",
    "    plot_metrics(metrics_history, output_folder)\n",
    "    return metrics_history\n",
    "\n",
    "def create_binary_masks(image_path):\n",
    "    \"\"\"Create binary masks using traditional CV method\"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    lower_bound = np.array([35, 40, 20])\n",
    "    upper_bound = np.array([85, 255, 255])\n",
    "    mask = cv2.inRange(image, lower_bound, upper_bound)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Class\n",
    "class VegetationDataset(Dataset):\n",
    "    def __init__(self, image_paths, masks=None, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.masks = masks\n",
    "        self.transform = transform\n",
    "        # Load images immediately instead of using multiprocessing\n",
    "        self.loaded_images = {}\n",
    "        self.loaded_masks = {}\n",
    "        self._preload_images()\n",
    "    \n",
    "    def _preload_images(self):\n",
    "        for idx, path in enumerate(self.image_paths):\n",
    "            image = cv2.imread(path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            self.loaded_images[idx] = image\n",
    "            \n",
    "            if self.masks is not None:\n",
    "                self.loaded_masks[idx] = cv2.resize(self.masks[idx], (320, 320))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.loaded_images[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        if self.masks is not None:\n",
    "            mask = self.loaded_masks[idx]\n",
    "            mask = torch.FloatTensor(mask / 255.0)\n",
    "            mask = mask.unsqueeze(0)\n",
    "            return image, mask\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, model, device, transform):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    original_size = image.shape[:2]\n",
    "    \n",
    "    if transform:\n",
    "        image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        mask_pred = model(image_tensor)\n",
    "        mask_pred = mask_pred.squeeze().cpu().numpy()\n",
    "        mask_pred = cv2.resize(mask_pred, (original_size[1], original_size[0]))\n",
    "        mask_pred = (mask_pred > 0.5).astype(np.uint8) * 255\n",
    "    \n",
    "    return image, mask_pred\n",
    "\n",
    "def segment_image(image, mask):\n",
    "    segmented = cv2.bitwise_and(image, image, mask=mask)\n",
    "    return mask, segmented\n",
    "\n",
    "def estimate_carbon_sequestration(mask, pixel_area=0.01):  # pixel_area in square meters\n",
    "    \"\"\"\n",
    "    Calculate carbon sequestration based on vegetation area and biomass estimation\n",
    "    Args:\n",
    "        mask: Binary mask of vegetation\n",
    "        pixel_area: Area represented by each pixel in square meters\n",
    "    Returns:\n",
    "        Dictionary containing carbon sequestration metrics\n",
    "    \"\"\"\n",
    "    vegetation_area = np.sum(mask > 0) * pixel_area  # Total area in square meters\n",
    "    \n",
    "    # Biomass calculation constants\n",
    "    biomass_factor = 0.5  # Average biomass per square meter for vegetation\n",
    "    carbon_fraction = 0.47  # Standard carbon fraction in biomass\n",
    "    co2_conversion = 3.67  # Conversion factor from C to CO2\n",
    "    \n",
    "    # Calculate metrics\n",
    "    total_biomass = vegetation_area * biomass_factor  # kg\n",
    "    carbon_content = total_biomass * carbon_fraction  # kg C\n",
    "    co2_sequestered = carbon_content * co2_conversion  # kg CO2\n",
    "    \n",
    "    return {\n",
    "        'vegetation_area_m2': vegetation_area,\n",
    "        'biomass_kg': total_biomass,\n",
    "        'carbon_content_kg': carbon_content,\n",
    "        'co2_sequestered_kg': co2_sequestered\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_visualizations(all_visualizations, output_folder):\n",
    "    \"\"\"\n",
    "    Create and save visualizations with enhanced carbon sequestration metrics\n",
    "    \"\"\"\n",
    "    num_images = len(all_visualizations)\n",
    "    fig = plt.figure(figsize=(20, 5 * num_images))\n",
    "    \n",
    "    for idx, (image, mask, segmented, metrics) in enumerate(all_visualizations):\n",
    "        # Original image\n",
    "        plt.subplot(num_images, 4, idx*4 + 1)\n",
    "        plt.title(f\"Original {idx+1}\")\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Mask\n",
    "        plt.subplot(num_images, 4, idx*4 + 2)\n",
    "        plt.title(f\"Vegetation Mask {idx+1}\")\n",
    "        plt.imshow(mask, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Segmented image\n",
    "        plt.subplot(num_images, 4, idx*4 + 3)\n",
    "        plt.title(f\"Segmented Vegetation {idx+1}\")\n",
    "        plt.imshow(segmented)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Metrics text\n",
    "        plt.subplot(num_images, 4, idx*4 + 4)\n",
    "        plt.axis('off')\n",
    "        plt.text(0.1, 0.7, \n",
    "                f\"Area: {metrics['vegetation_area_m2']:.2f} m²\\n\"\n",
    "                f\"Biomass: {metrics['biomass_kg']:.2f} kg\\n\"\n",
    "                f\"Carbon: {metrics['carbon_content_kg']:.2f} kg C\\n\"\n",
    "                f\"CO₂ Seq: {metrics['co2_sequestered_kg']:.2f} kg CO₂\",\n",
    "                fontsize=10, fontfamily='monospace')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_folder, 'all_results.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Save individual results\n",
    "    individual_dir = os.path.join(output_folder, 'individual_results')\n",
    "    os.makedirs(individual_dir, exist_ok=True)\n",
    "    \n",
    "    for idx, (image, mask, segmented, metrics) in enumerate(all_visualizations):\n",
    "        # Save metrics to CSV\n",
    "        metrics_file = os.path.join(individual_dir, f'metrics_{idx+1}.csv')\n",
    "        with open(metrics_file, 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['Metric', 'Value'])\n",
    "            for key, value in metrics.items():\n",
    "                writer.writerow([key, f'{value:.2f}'])\n",
    "        \n",
    "        # Save images\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        \n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(image)\n",
    "        plt.title(f\"Original {idx+1}\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(mask, cmap='gray')\n",
    "        plt.title(f\"Mask {idx+1}\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(segmented)\n",
    "        plt.title(f\"Segmented {idx+1}\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.savefig(os.path.join(individual_dir, f'result_{idx+1}.png'), \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_device():\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"Using MPS backend for Mac GPU acceleration\")\n",
    "    elif torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(\"Using CUDA GPU acceleration\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU\")\n",
    "    return device\n",
    "\n",
    "def get_training_config():\n",
    "    return {\n",
    "        'batch_size': 8,  # Increased batch size for faster processing\n",
    "        'num_workers': 2,  # Added some workers for data loading\n",
    "        'pin_memory': True,\n",
    "        'prefetch_factor': 2,  # Add prefetching for better data loading\n",
    "    }\n",
    "\n",
    "# Create data loaders with simplest configuration\n",
    "def create_data_loaders(train_dataset, val_dataset, train_config):\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=train_config['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        pin_memory=train_config['pin_memory']\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=train_config['batch_size'],\n",
    "        num_workers=0,\n",
    "        pin_memory=train_config['pin_memory']\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "def get_transform():\n",
    "    return Compose([\n",
    "        ToTensor(),\n",
    "        Resize((320, 320), antialias=True),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                 std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "def main():\n",
    "    # Setup paths\n",
    "    train_data_folder = 'dataset/train'  # Path to training data\n",
    "    val_data_folder = 'dataset/test'     # Add missing val_data_folder\n",
    "    output_folder = 'result'             # Add missing output_folder\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Get device\n",
    "    device = setup_device()\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    train_config = get_training_config()\n",
    "    \n",
    "    # Data preparation with pre-split data\n",
    "    print(\"Preparing dataset...\")\n",
    "    train_image_paths = []\n",
    "    train_masks = []\n",
    "    val_image_paths = []\n",
    "    val_masks = []\n",
    "    \n",
    "    # Load training data\n",
    "    for file_name in os.listdir(train_data_folder):\n",
    "        if file_name.lower().endswith(('.jpg', '.png')):\n",
    "            file_path = os.path.join(train_data_folder, file_name)\n",
    "            mask = create_binary_masks(file_path)\n",
    "            train_image_paths.append(file_path)\n",
    "            train_masks.append(mask)\n",
    "    \n",
    "    # Load validation data\n",
    "    for file_name in os.listdir(val_data_folder):\n",
    "        if file_name.lower().endswith(('.jpg', '.png')):\n",
    "            file_path = os.path.join(val_data_folder, file_name)\n",
    "            mask = create_binary_masks(file_path)\n",
    "            val_image_paths.append(file_path)\n",
    "            val_masks.append(mask)\n",
    "    \n",
    "    # Optimized transform for M1\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((320, 320), antialias=True),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                           std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Create optimized datasets\n",
    "    train_dataset = VegetationDataset(train_image_paths, train_masks, transform=transform)\n",
    "    val_dataset = VegetationDataset(val_image_paths, val_masks, transform=transform)\n",
    "    \n",
    "    # Create data loaders using the helper function\n",
    "    train_loader, val_loader = create_data_loaders(train_dataset, val_dataset, train_config)\n",
    "    \n",
    "    # Ensure model weights are on correct device\n",
    "    model = ImprovedSegmentationModel()\n",
    "    model = model.to(device)  # Simplified device transfer\n",
    "    \n",
    "    # Ensure model weights are on correct device\n",
    "    for param in model.parameters():\n",
    "        param.data = param.data.to(device)\n",
    "    \n",
    "    # Initialize training components with pure Dice Loss\n",
    "    criterion = DiceLoss()\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=0.001,  # Slightly higher learning rate\n",
    "        weight_decay=0.01,\n",
    "        betas=(0.9, 0.999)\n",
    "    )\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='min',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        verbose=True,\n",
    "        min_lr=1e-6\n",
    "    )\n",
    "    \n",
    "    # Training\n",
    "    print(\"Starting training...\")\n",
    "    # Train the model\n",
    "    metrics_history = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        num_epochs=100,\n",
    "        device=device,\n",
    "        output_folder=output_folder\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Process test images\n",
    "    print(\"Processing test images...\")\n",
    "    test_images = []\n",
    "    \n",
    "    # Process all test images (remove the break condition)\n",
    "    for file_name in os.listdir(val_data_folder):\n",
    "        if file_name.lower().endswith(('.jpg', '.png')):\n",
    "            file_path = os.path.join(val_data_folder, file_name)\n",
    "            image, mask_pred = preprocess_image(file_path, model, device, transform)\n",
    "            mask, segmented = segment_image(image, mask_pred)\n",
    "            \n",
    "            metrics = estimate_carbon_sequestration(mask)\n",
    "            test_images.append((image, mask, segmented, metrics))\n",
    "            \n",
    "            print(f\"\\nFile: {file_name}\")\n",
    "            print(f\"Vegetation Area: {metrics['vegetation_area_m2']:.2f} m²\")\n",
    "            print(f\"Estimated Biomass: {metrics['biomass_kg']:.2f} kg\")\n",
    "            print(f\"Carbon Content: {metrics['carbon_content_kg']:.2f} kg C\")\n",
    "            print(f\"CO₂ Sequestered: {metrics['co2_sequestered_kg']:.2f} kg CO₂\")\n",
    "    \n",
    "    # Create visualizations for all images\n",
    "    if test_images:\n",
    "        create_visualizations(test_images, output_folder)\n",
    "        print(f\"\\nVisualization and metrics saved to {output_folder}\")\n",
    "    else:\n",
    "        print(\"No test images were processed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Read the CO2 sequestration data\n",
    "df = pd.read_csv('result/CO2_seq.csv')\n",
    "\n",
    "# Function to determine trend and additional metrics\n",
    "def analyze_trend(values, window_size=20):\n",
    "    # Remove NaN values\n",
    "    values = values.dropna()\n",
    "    \n",
    "    # Basic trend\n",
    "    x = np.arange(len(values))\n",
    "    coefficients = np.polyfit(x, values, 1)\n",
    "    trend = 'INCREASING' if coefficients[0] > 0 else 'DECREASING'\n",
    "    \n",
    "    # Calculate short-term trends using rolling windows\n",
    "    rolling_means = values.rolling(window=window_size).mean()\n",
    "    short_term_trends = rolling_means.diff().apply(lambda x: 'INCREASING' if x > 0 else 'DECREASING')\n",
    "    \n",
    "    return {\n",
    "        'Overall_Trend': trend,\n",
    "        'Rate_of_Change': coefficients[0],\n",
    "        'Current_Value': values.iloc[-1],\n",
    "        'Mean': values.mean(),\n",
    "        'Max': values.max(),\n",
    "        'Min': values.min(),\n",
    "        'Std_Dev': values.std(),\n",
    "        'Short_Term_Trends': short_term_trends\n",
    "    }\n",
    "\n",
    "# Calculate metrics for different aspects\n",
    "time_periods = df.index\n",
    "trend_data = []\n",
    "\n",
    "# Analyze different metrics\n",
    "metrics = {\n",
    "    'Carbon_Sequestration': df['carbon_sequestration'],\n",
    "    'Moving_Average': df['carbon_sequestration'].rolling(window=20).mean(),\n",
    "    'Running_Total': df['carbon_sequestration'].cumsum(),\n",
    "    'Running_Average': df['carbon_sequestration'].expanding().mean()\n",
    "}\n",
    "\n",
    "# Analyze each metric\n",
    "for metric_name, values in metrics.items():\n",
    "    analysis = analyze_trend(values)\n",
    "    \n",
    "    # Create trend data for each time period\n",
    "    for period in time_periods:\n",
    "        trend_data.append({\n",
    "            'Time_Period': period,\n",
    "            'Metric': metric_name,\n",
    "            'Value': values.iloc[period] if period < len(values) else None,\n",
    "            'Overall_Trend': analysis['Overall_Trend'],\n",
    "            'Rate_of_Change': analysis['Rate_of_Change'],\n",
    "            'Short_Term_Trend': analysis['Short_Term_Trends'].iloc[period] if period < len(analysis['Short_Term_Trends']) else None\n",
    "        })\n",
    "\n",
    "# Create DataFrame and save to CSV\n",
    "trend_df = pd.DataFrame(trend_data)\n",
    "trend_df.to_csv('result/trend_analysis.csv', index=False)\n",
    "\n",
    "# Create visualizations with trend indicators\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, (metric_name, values) in enumerate(metrics.items()):\n",
    "    ax = axes[idx]\n",
    "    analysis = analyze_trend(values)\n",
    "    \n",
    "    # Plot main values\n",
    "    ax.plot(values, label=metric_name)\n",
    "    \n",
    "    # Add trend line\n",
    "    x = np.arange(len(values.dropna()))\n",
    "    trend_line = analysis['Rate_of_Change'] * x + np.polyfit(x, values.dropna(), 1)[1]\n",
    "    ax.plot(x, trend_line, '--', \n",
    "           label=f\"Trend ({analysis['Overall_Trend']})\\nRate: {analysis['Rate_of_Change']:.4f}\")\n",
    "    \n",
    "    ax.set_title(f\"{metric_name.replace('_', ' ')} Analysis\")\n",
    "    ax.set_xlabel('Time Period')\n",
    "    ax.set_ylabel('Value')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('result/trend_analysis_plots.png')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Trend analysis has been saved to 'result/trend_analysis.csv'\")\n",
    "print(f\"Visualization has been saved to 'result/trend_analysis_plots.png'\")\n",
    "\n",
    "# Display sample of the trend analysis\n",
    "print(\"\\nSample of trend analysis data:\")\n",
    "print(trend_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
